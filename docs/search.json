[
  {
    "objectID": "Aula2.html",
    "href": "Aula2.html",
    "title": "Pacotes",
    "section": "",
    "text": "O carregamento de pacotes pode ser feito pelo menu ou então com um comando no console. O fluxo básico da programação pode ser conferido neste link.\nLibrary é o nome da função que carrega um pacote.\nInstal.package instala o pacote\nAbaixo demonstraremos como instalar e carregar um pacote.\n\nlibrary(tidyverse)\nlibrary(metafor)\nlibrary(gsheet)\nlibrary(dplyr)\n\nA função gsheet2tbl url carrega um dado que está na nuvem\ninstall_github(“emdelponte/r4pde”) : instala um pacote do github\n\narrange(mtcars, -mpg)\n\n                     mpg cyl  disp  hp drat    wt  qsec vs am gear carb\nToyota Corolla      33.9   4  71.1  65 4.22 1.835 19.90  1  1    4    1\nFiat 128            32.4   4  78.7  66 4.08 2.200 19.47  1  1    4    1\nHonda Civic         30.4   4  75.7  52 4.93 1.615 18.52  1  1    4    2\nLotus Europa        30.4   4  95.1 113 3.77 1.513 16.90  1  1    5    2\nFiat X1-9           27.3   4  79.0  66 4.08 1.935 18.90  1  1    4    1\nPorsche 914-2       26.0   4 120.3  91 4.43 2.140 16.70  0  1    5    2\nMerc 240D           24.4   4 146.7  62 3.69 3.190 20.00  1  0    4    2\nDatsun 710          22.8   4 108.0  93 3.85 2.320 18.61  1  1    4    1\nMerc 230            22.8   4 140.8  95 3.92 3.150 22.90  1  0    4    2\nToyota Corona       21.5   4 120.1  97 3.70 2.465 20.01  1  0    3    1\nHornet 4 Drive      21.4   6 258.0 110 3.08 3.215 19.44  1  0    3    1\nVolvo 142E          21.4   4 121.0 109 4.11 2.780 18.60  1  1    4    2\nMazda RX4           21.0   6 160.0 110 3.90 2.620 16.46  0  1    4    4\nMazda RX4 Wag       21.0   6 160.0 110 3.90 2.875 17.02  0  1    4    4\nFerrari Dino        19.7   6 145.0 175 3.62 2.770 15.50  0  1    5    6\nMerc 280            19.2   6 167.6 123 3.92 3.440 18.30  1  0    4    4\nPontiac Firebird    19.2   8 400.0 175 3.08 3.845 17.05  0  0    3    2\nHornet Sportabout   18.7   8 360.0 175 3.15 3.440 17.02  0  0    3    2\nValiant             18.1   6 225.0 105 2.76 3.460 20.22  1  0    3    1\nMerc 280C           17.8   6 167.6 123 3.92 3.440 18.90  1  0    4    4\nMerc 450SL          17.3   8 275.8 180 3.07 3.730 17.60  0  0    3    3\nMerc 450SE          16.4   8 275.8 180 3.07 4.070 17.40  0  0    3    3\nFord Pantera L      15.8   8 351.0 264 4.22 3.170 14.50  0  1    5    4\nDodge Challenger    15.5   8 318.0 150 2.76 3.520 16.87  0  0    3    2\nMerc 450SLC         15.2   8 275.8 180 3.07 3.780 18.00  0  0    3    3\nAMC Javelin         15.2   8 304.0 150 3.15 3.435 17.30  0  0    3    2\nMaserati Bora       15.0   8 301.0 335 3.54 3.570 14.60  0  1    5    8\nChrysler Imperial   14.7   8 440.0 230 3.23 5.345 17.42  0  0    3    4\nDuster 360          14.3   8 360.0 245 3.21 3.570 15.84  0  0    3    4\nCamaro Z28          13.3   8 350.0 245 3.73 3.840 15.41  0  0    3    4\nCadillac Fleetwood  10.4   8 472.0 205 2.93 5.250 17.98  0  0    3    4\nLincoln Continental 10.4   8 460.0 215 3.00 5.424 17.82  0  0    3    4\n\nOrange\n\nGrouped Data: circumference ~ age | Tree\n   Tree  age circumference\n1     1  118            30\n2     1  484            58\n3     1  664            87\n4     1 1004           115\n5     1 1231           120\n6     1 1372           142\n7     1 1582           145\n8     2  118            33\n9     2  484            69\n10    2  664           111\n11    2 1004           156\n12    2 1231           172\n13    2 1372           203\n14    2 1582           203\n15    3  118            30\n16    3  484            51\n17    3  664            75\n18    3 1004           108\n19    3 1231           115\n20    3 1372           139\n21    3 1582           140\n22    4  118            32\n23    4  484            62\n24    4  664           112\n25    4 1004           167\n26    4 1231           179\n27    4 1372           209\n28    4 1582           214\n29    5  118            30\n30    5  484            49\n31    5  664            81\n32    5 1004           125\n33    5 1231           142\n34    5 1372           174\n35    5 1582           177\n\nd <- gsheet2tbl('docs.google.com/spreadsheets/d/1I9mJsS5QnXF2TNNntTy-HrcdHmIF9wJ8ONYvEJTXSNo')\n\n\n url <- 'docs.google.com/spreadsheets/d/1I9mJsS5QnXF2TNNntTy-HrcdHmIF9wJ8ONYvEJTXSNo'\nmtcars <- gsheet2tbl(url)\n\nb <- mtcars\nc = b\n\nlibrary(remotes)\nhead(mtcars)\n\n# A tibble: 6 × 11\n    mpg   cyl  disp    hp  drat    wt  qsec    vs    am  gear  carb\n  <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl>\n1  21       6   160   110  3.9   2.62  16.5     0     1     4     4\n2  21       6   160   110  3.9   2.88  17.0     0     1     4     4\n3  22.8     4   108    93  3.85  2.32  18.6     1     1     4     1\n4  21.4     6   258   110  3.08  3.22  19.4     1     0     3     1\n5  18.7     8   360   175  3.15  3.44  17.0     0     0     3     2\n6  18.1     6   225   105  2.76  3.46  20.2     1     0     3     1\n\ntail(mtcars)\n\n# A tibble: 6 × 11\n    mpg   cyl  disp    hp  drat    wt  qsec    vs    am  gear  carb\n  <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl>\n1  26       4 120.     91  4.43  2.14  16.7     0     1     5     2\n2  30.4     4  95.1   113  3.77  1.51  16.9     1     1     5     2\n3  15.8     8 351     264  4.22  3.17  14.5     0     1     5     4\n4  19.7     6 145     175  3.62  2.77  15.5     0     1     5     6\n5  15       8 301     335  3.54  3.57  14.6     0     1     5     8\n6  21.4     4 121     109  4.11  2.78  18.6     1     1     4     2\n\n\nA funçao head vai listar somente as seis primeiras linhas do dataframe.\nPara ver as ultimas linhas é tail.\n\nlibrary(r4pde)\nunit <- c(1:12)\nclass <- c(2,3,1,1,3,4,5,0,2,5,2,1)\nratings <- data.frame(unit, class)\nDSI(unit = ratings$unit, class = ratings$class, max = 6)\n\n[1] 40.27778\n\nratings$class\n\n [1] 2 3 1 1 3 4 5 0 2 5 2 1\n\nmean(ratings$class)\n\n[1] 2.416667\n\nsd(ratings$class)\n\n[1] 1.621354\n\nsummary(ratings$class)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  0.000   1.000   2.000   2.417   3.250   5.000 \n\n\nAlgumas informações importantes:\nData.frame cria uma base de dados (vetor unidade, vetor classe) e formar o data frame.\nEx:\nunit <- c(1:12) > esta criando um conjunto de observações em uma variável.\nA função DSI, espera a unidade a classe e o valor máximo ratings$unit : o cifrão é variável unit da dataframe ratings.\nArgumentos sempre são separados por vírgula."
  },
  {
    "objectID": "Aula3.html",
    "href": "Aula3.html",
    "title": "Importação de dados",
    "section": "",
    "text": "cars\n\n   speed dist\n1      4    2\n2      4   10\n3      7    4\n4      7   22\n5      8   16\n6      9   10\n7     10   18\n8     10   26\n9     10   34\n10    11   17\n11    11   28\n12    12   14\n13    12   20\n14    12   24\n15    12   28\n16    13   26\n17    13   34\n18    13   34\n19    13   46\n20    14   26\n21    14   36\n22    14   60\n23    14   80\n24    15   20\n25    15   26\n26    15   54\n27    16   32\n28    16   40\n29    17   32\n30    17   40\n31    17   50\n32    18   42\n33    18   56\n34    18   76\n35    18   84\n36    19   36\n37    19   46\n38    19   68\n39    20   32\n40    20   48\n41    20   52\n42    20   56\n43    20   64\n44    22   66\n45    23   54\n46    24   70\n47    24   92\n48    24   93\n49    24  120\n50    25   85\n\ncars2 <- cars\nspeed <- cars2$speed\nspeed\n\n [1]  4  4  7  7  8  9 10 10 10 11 11 12 12 12 12 13 13 13 13 14 14 14 14 15 15\n[26] 15 16 16 17 17 17 18 18 18 18 19 19 19 20 20 20 20 20 22 23 24 24 24 24 25\n\n\n\nlibrary(r4pde)\nRustSoybean\n\n# A tibble: 34 × 7\n   epidemia latitude longitude local              planting   detection  severity\n      <dbl>    <dbl>     <dbl> <chr>              <date>     <date>        <dbl>\n 1       23    -23.0     -50.1 Cambara            2003-11-25 2004-02-02     24  \n 2       24    -24.0     -52.4 Campo Mourao       2003-11-28 2004-02-02     21  \n 3       31    -15.5     -55.2 Campo Verde        2004-11-20 2005-01-25     78  \n 4        3    -13.3     -44.6 Correntina         2002-11-10 2003-01-03     85  \n 5       15    -13.3     -44.6 Correntina         2003-11-28 2004-01-31     25  \n 6       34    -25.4     -51.5 Guarapuava         2004-11-29 2005-03-14     32  \n 7        7    -29.2     -53.7 Julio Castilhos    2002-12-15 2003-04-10     40  \n 8       13    -12.1     -45.8 Luis Eduardo Maga… 2003-11-12 2004-02-15     39.2\n 9       33    -12.1     -45.8 Luis Eduardo Maga… 2004-11-19 2005-01-25     55  \n10        1    -23.3     -51.2 Londrina           2002-11-06 2003-02-03     45  \n# ℹ 24 more rows\n\ndf <- RustSoybean\ndf\n\n# A tibble: 34 × 7\n   epidemia latitude longitude local              planting   detection  severity\n      <dbl>    <dbl>     <dbl> <chr>              <date>     <date>        <dbl>\n 1       23    -23.0     -50.1 Cambara            2003-11-25 2004-02-02     24  \n 2       24    -24.0     -52.4 Campo Mourao       2003-11-28 2004-02-02     21  \n 3       31    -15.5     -55.2 Campo Verde        2004-11-20 2005-01-25     78  \n 4        3    -13.3     -44.6 Correntina         2002-11-10 2003-01-03     85  \n 5       15    -13.3     -44.6 Correntina         2003-11-28 2004-01-31     25  \n 6       34    -25.4     -51.5 Guarapuava         2004-11-29 2005-03-14     32  \n 7        7    -29.2     -53.7 Julio Castilhos    2002-12-15 2003-04-10     40  \n 8       13    -12.1     -45.8 Luis Eduardo Maga… 2003-11-12 2004-02-15     39.2\n 9       33    -12.1     -45.8 Luis Eduardo Maga… 2004-11-19 2005-01-25     55  \n10        1    -23.3     -51.2 Londrina           2002-11-06 2003-02-03     45  \n# ℹ 24 more rows\n\n\n\n\n\nO segundo argumento é o nome da aba do arquivo excel\n\nlibrary(readxl)\nmagnesio <- read_excel(\"dados-diversos.xlsx\")\nescala <- read_excel(\"dados-diversos.xlsx\", \"escala\")\nescala <- read_excel(\"dados-diversos.xlsx\", 2)\n\n\n\n\nFormato csv é formato de texto, separado por vírgula. Quando pede ajuda vai aparecer: read.table {utils} entre chaves é o nome do pacote Se não der tenta read_csv2, porque pode estar separado por outro caractere\n\nmagnesio2 <- read.csv(\"dados-diversos.csv\")\nlibrary(tidyverse)\nmagnesio5 <- read_csv(\"dados-diversos.csv\")\n\n#From txt\n\nmagnesio6 <- read.table(\"dados-diversos.txt\", header = TRUE)\nmagnesio6\n\n   Irrigation rep day severity\n1      Furrow   1   0     0,01\n2      Furrow   2   0     0,01\n3      Furrow   3   0     0,01\n4      Furrow   1   7     0,04\n5      Furrow   2   7     0,04\n6      Furrow   3   7     0,04\n7      Furrow   1  14     0,10\n8      Furrow   2  14     0,10\n9      Furrow   3  14     0,11\n10     Furrow   1  21     0,11\n11     Furrow   2  21     0,10\n12     Furrow   3  21     0,10\n13     Furrow   1  28     0,15\n14     Furrow   2  28     0,17\n15     Furrow   3  28     0,15\n16     Furrow   1  35     0,18\n17     Furrow   2  35     0,19\n18     Furrow   3  35     0,19\n19     Furrow   1  42     0,34\n20     Furrow   2  42     0,38\n21     Furrow   3  42     0,34\n22     Furrow   1  49     0,38\n23     Furrow   2  49     0,39\n24     Furrow   3  49     0,38\n25     Furrow   1  56     0,40\n26     Furrow   2  56     0,41\n27     Furrow   3  56     0,43\n28     Furrow   1  63     0,46\n29     Furrow   2  63     0,46\n30     Furrow   3  63     0,43\n31       Drip   1   0     0,01\n32       Drip   2   0     0,01\n33       Drip   3   0     0,01\n34       Drip   1   7     0,03\n35       Drip   2   7     0,04\n36       Drip   3   7     0,04\n37       Drip   1  14     0,11\n38       Drip   2  14     0,11\n39       Drip   3  14     0,10\n40       Drip   1  21     0,13\n41       Drip   2  21     0,12\n42       Drip   3  21     0,10\n43       Drip   1  28     0,16\n44       Drip   2  28     0,15\n45       Drip   3  28     0,15\n46       Drip   1  35     0,18\n47       Drip   2  35     0,19\n48       Drip   3  35     0,17\n49       Drip   1  42     0,30\n50       Drip   2  42     0,33\n51       Drip   3  42     0,34\n52       Drip   1  49     0,33\n53       Drip   2  49     0,37\n54       Drip   3  49     0,37\n55       Drip   1  56     0,39\n56       Drip   2  56     0,46\n57       Drip   3  56     0,41\n58       Drip   1  63     0,43\n59       Drip   2  63     0,43\n60       Drip   3  63     0,43"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "",
    "section": "",
    "text": "Este site foi criado na disciplina FIP - 606 com Quarto.\nAs aulas da disciplina estão disponibilizadas nos itens do menu."
  },
  {
    "objectID": "index.html#análise-e-visualização-de-dados-em-fitopatologia",
    "href": "index.html#análise-e-visualização-de-dados-em-fitopatologia",
    "title": "",
    "section": "Análise e visualização de dados em Fitopatologia",
    "text": "Análise e visualização de dados em Fitopatologia\nA disciplina FIP 606 é ofertada pelo curso de pós-graduação em Fitopatologia da Universidade Federal de Viçosa e aborda:\nConceitos básicos de estatística. Metodologia Científica. Escolha de delineamentos e análise de variância de experimentos conduzidos em condições de laboratórios, casa de vegetação e campo, em diferentes áreas na Fitopatologia. Análise de regressão e correlação aplicada à Fitopatologia. Análise multivariada. Aplicações de programas de computador em análises estatísticas.\nPara saber mais sobre o curso de pós-graduação clique aqui.\nDisciplina ministrada por:"
  },
  {
    "objectID": "index.html#prof.-emerson-del-ponte",
    "href": "index.html#prof.-emerson-del-ponte",
    "title": "",
    "section": "Prof. Emerson Del Ponte",
    "text": "Prof. Emerson Del Ponte\nDr. em Fitopatologia, UFPel/Cornell (sandwich)  (2004)\nM.Sc. em Agronomia, UFPel (1999)\nEng. Agrônomo, UFPel (1996)\n GitHub  Instagram"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "Sabrina Angela Cassol",
    "section": "",
    "text": "Doutoranda em fitopatologia, no laboratório de biologia molecular florestal, trabalhando com o patossistema Ceratocystis fimbriata - Actinidia spp.\n\nFormação\nAgrônoma - Instituto Federal Catarinense (2021)\nMestre em Fitopatologia - Universidade Federal de Viçosa (2023)\nDoutoranda em Fitopatologia - Universidade Federal de Viçosa"
  },
  {
    "objectID": "Aula4.html",
    "href": "Aula4.html",
    "title": "GGplot",
    "section": "",
    "text": "Quando coloca |> você já ta dentro dos dados. Você não precisa colocar o argumento dados no primeiro argumento do ggplot.\n\nlibrary(tidyverse)\nmg <- read_csv(\"dados-diversos.csv\")\n\nAlterando a cor de cada fator\n\nmg |> \n  ggplot(aes(Irrigation, severity,\n             color = Irrigation)) +\n  geom_point()\n\n\n\n\nAlterando o símbolo alpha, dois valores iguais ficam de outra cor, quanto mais escuro mais pontos\n\nmg |> \n  ggplot(aes(Irrigation, severity,\n             shape = Irrigation, color = Irrigation)) +\n  geom_point(alpha = 0.5)\n\n\n\n\nAlterando agora o gráfico e filtrando cada repetição filter filtra linhas\n\nmg |> \n  filter(rep == 1) |>\n  ggplot(aes(day, severity,\n             shape = Irrigation)) +\n  geom_point(alpha = 0.5) +\n  geom_line() \n\n\n\n\nAlterando agora o gráfico, criando uma face pra cada repetição\n\nmg |> \n  ggplot(aes(day, severity,\n             shape = Irrigation)) +\n  geom_point(alpha = 0.5) +\n  geom_line() +\n  facet_wrap(~rep)\n\n\n\n\nFiltrando variáveis com select(var1, var2) neste gráfico não tem nenhum outline, fora das linhas do box. group = esta criando pra cada dia\n\nmg |> \n  select(day, rep, severity) |>\n\n  ggplot(aes(day, severity,\n             group=day)) +\n    geom_point() \n\n\n\n\nCalculando o valor médio das repetições group = agrupou severidade por dia. summarize(definiu que seria a média de severidade e criou a variável “sev”) ficou duas variáveis dias e média de severidade mudei severidade pra porcentagem só multiplicando por 100 ylim: coloca o limite do y Temas pra mudar: theme_light theme_minimal scale_x_continuos : muda a escala do eixo x\n\nmg2 <- mg |> \n  select(day, rep, severity) |>\n  group_by(day) |>\n  summarize(sev = mean(severity)) \n\nmg2 |>\n  ggplot(aes(day, sev*100)) +\n  geom_line(color = \"darkorange\") +\n    geom_point(size = 2,\n               color = \"darkorange\") +\n      scale_x_continuous(breaks = c(0,7,14,21,28,35,42,49,56,63)) +\n      scale_y_continuous(n.breaks = 5, limits = c(0,100)) +\n      labs(x = \"Time (days)\", y = \"Severity (%)\", title= \"My first ggplot\",         subtitle= \"It is beautiful\", caption = \"Source: FIP 606\") +\n      theme_minimal()\n\n\n\n      ggsave(\"myfistggplot.png\", bg = \"white\",\n             width = 4,\n             height = 3)\n\nCriando pra cada tipo de irrigação\n\nlibrary(MetBrewer)\n\nmg5 <- mg |> \n  group_by(day, Irrigation) |>\n  summarize(sev = mean(severity)) \n\nm <- mg5 |>\n  ggplot(aes(day, sev*100, color= Irrigation)) +\n  geom_line() +\n      scale_x_continuous(breaks = c(0,7,14,21,28,35,42,49,56,63)) +\n      scale_y_continuous(n.breaks = 5, limits = c(0,100)) +\n      labs(x = \"Time (days)\", y = \"Severity (%)\", title= \"GGplot2\",  \n           subtitle= \"With two irrigations\", caption = \"Source: FIP 606\") +\n      theme_minimal()+\n      scale_color_manual(values = met.brewer(\"Java\"))\n      ggsave(\"myfistggplot2.png\", bg = \"white\",\n             width = 4,\n             height = 3)\n\n      mg5\n\n# A tibble: 20 × 3\n# Groups:   day [10]\n     day Irrigation    sev\n   <dbl> <chr>       <dbl>\n 1     0 Drip       0.01  \n 2     0 Furrow     0.01  \n 3     7 Drip       0.0367\n 4     7 Furrow     0.04  \n 5    14 Drip       0.107 \n 6    14 Furrow     0.103 \n 7    21 Drip       0.117 \n 8    21 Furrow     0.103 \n 9    28 Drip       0.153 \n10    28 Furrow     0.157 \n11    35 Drip       0.18  \n12    35 Furrow     0.187 \n13    42 Drip       0.323 \n14    42 Furrow     0.353 \n15    49 Drip       0.357 \n16    49 Furrow     0.383 \n17    56 Drip       0.42  \n18    56 Furrow     0.413 \n19    63 Drip       0.43  \n20    63 Furrow     0.45"
  },
  {
    "objectID": "Aula4.html#visualiza",
    "href": "Aula4.html#visualiza",
    "title": "GGplot",
    "section": "Visualiza",
    "text": "Visualiza\nfunção geom-jitter separa os pontos, diferente do geom_point que sobrepõem, e width é a largura entre os pontos scale_y_continuous > pra definir a escala do y"
  },
  {
    "objectID": "Aula4.html#salvar-dois-gráficos-juntos",
    "href": "Aula4.html#salvar-dois-gráficos-juntos",
    "title": "GGplot",
    "section": "Salvar dois gráficos juntos",
    "text": "Salvar dois gráficos juntos\nse colocar um | outro = vai ficar um do lado do outro se colocar um / outro = vai ficar um em cima do outro\n\nlibrary(patchwork)\n(m | pmeans) +\n  plot_annotation(tag_levels = 'A', title= 'Gráficos que impressionam')\n\n\n\n  ggsave(\"figs/combined.png\",\n          bg = \"white\", width = 6, height= 4)\n\nBarras laterais\n\nsurvey <- read_excel(\"dados-diversos.xlsx\", \n                     sheet= \"survey\")\nsurvey |>\n   filter(state == \"RS\") |>\n   count(species, residue) |>\n  ggplot(aes(species, n))+\n  geom_col(width = 0.4)+\n  coord_flip()+\n  facet_wrap(~residue, ncol= 1)+\n  theme_bw()+\n  labs(x = NULL, y = \"Number of isolates\", title= \"Horizontal bar plot\")\n\n\n\n  ggsave(\"figs/barplotfacewrap.png\",\n          bg = \"white\", width = 6, height= 4)"
  },
  {
    "objectID": "Aula8.html",
    "href": "Aula8.html",
    "title": "Teste T",
    "section": "",
    "text": "library(tidyverse)\nlibrary(readxl)\nlibrary(ggplot2)\nmg <- read_excel(\"dados-diversos.xlsx\")\n\nmg |>\n  ggplot(aes(trat, comp))+\n  geom_jitter(width = 0.05)+\n  geom_boxplot(fill = NA,\n               outlier.colour = NA)+\n    ylim(5, 20)+\n  annotate(geom = \"text\",\n           x = 0.6, y = 20,\n           label = \"p < 0.001 t = 8.12\")\n\n\n\n\nDataframe precisar ser no formato largo: cada tratamento em uma coluna primeiro\npivot_wider: pega os nomes de tratamento e os valores de comprimento\n\nmg2 <- mg |>\n   pivot_wider(1,\n               names_from = trat,\n               values_from = comp)\n\nTeste T\nPacote report mostra como colocar no artigo\n\nt <- t.test(mg2$Mg2, mg2$control)\n\nlibrary(report)\nreport(t)\n\nEffect sizes were labelled following Cohen's (1988) recommendations.\n\nThe Welch Two Sample t-test testing the difference between mg2$Mg2 and\nmg2$control (mean of x = 10.52, mean of y = 15.68) suggests that the effect is\nnegative, statistically significant, and large (difference = -5.16, 95% CI\n[-6.49, -3.83], t(17.35) = -8.15, p < .001; Cohen's d = -3.65, 95% CI [-5.12,\n-2.14])\n\n\n\nmg |>\n    ggplot(aes(trat, comp))+\n  stat_summary(fun.data = \"mean_se\")\n\n\n\n\nOutro exemplo\n\nmg <- read_excel(\"dados-diversos.xlsx\")\n\n\ndat2 <- mg %>%\n  group_by(trat) %>%\n  summarise(\n    mean_comp = mean(comp),\n    sd_comp = sd(comp),\n    var_comp = var(comp),\n    n = n(),\n    se_comp = sd_comp / sqrt(n -1),\n    ci = se_comp * qt(0.975, df = 9) # paramétrico\n  )\n\n\ndat2 |>\n  ggplot(aes(trat, mean_comp))+\n  geom_col(width = 0.5, color = \"blue\", fill = \"blue\") +\n geom_errorbar(aes(\n   ymin = mean_comp - se_comp,\n   ymax = mean_comp + se_comp, width = 0.05)\n ) +\n ylim(0,20)+\n  theme_classic()+\n  labs(x = NULL, y = \"Lesion size (mm)\")\n\n\n\n  ggsave(\"figs/barplotfacewrap.png\",\n          bg = \"white\", width = 6, height= 4)\n\n\nmg2 <- mg %>%\n  pivot_wider(1, names_from = trat, values_from = comp)\n\npaired = grupos independentes.\n\nt <- t.test(mg2$Mg2, mg2$control, paired = F)\n\nlibrary(report)\nreport(t)\n\nEffect sizes were labelled following Cohen's (1988) recommendations.\n\nThe Welch Two Sample t-test testing the difference between mg2$Mg2 and\nmg2$control (mean of x = 10.52, mean of y = 15.68) suggests that the effect is\nnegative, statistically significant, and large (difference = -5.16, 95% CI\n[-6.49, -3.83], t(17.35) = -8.15, p < .001; Cohen's d = -3.65, 95% CI [-5.12,\n-2.14])\n\n\nHomocedesticidade attach separa as variaveis\n\nattach(mg2) # vamos facilitar o uso dos dados\nvar.test(Mg2, control)\n\n\n    F test to compare two variances\n\ndata:  Mg2 and control\nF = 1.4781, num df = 9, denom df = 9, p-value = 0.5698\nalternative hypothesis: true ratio of variances is not equal to 1\n95 percent confidence interval:\n 0.3671417 5.9508644\nsample estimates:\nratio of variances \n          1.478111 \n\n\nTestar normalidade\n\nshapiro.test(Mg2)\n\n\n    Shapiro-Wilk normality test\n\ndata:  Mg2\nW = 0.97269, p-value = 0.9146\n\nshapiro.test(control)\n\n\n    Shapiro-Wilk normality test\n\ndata:  control\nW = 0.93886, p-value = 0.5404\n\n\nAnálise visual da premissa de normalidade\n\nqqnorm(Mg2)\nqqline(Mg2)\n\n\n\nqqnorm(control)\nqqline(control)\n\n\n\n\n\nescala <- read_excel(\"dados-diversos.xlsx\", \"escala\")\nhead(escala)\n\n# A tibble: 6 × 7\n  assessment rater acuracia precisao vies_geral vies_sistematico vies_constante\n  <chr>      <chr>    <dbl>    <dbl>      <dbl>            <dbl>          <dbl>\n1 Unaided    A        0.809    0.826      0.979            1.19         0.112  \n2 Unaided    B        0.722    0.728      0.991            0.922       -0.106  \n3 Unaided    C        0.560    0.715      0.783            1.16         0.730  \n4 Unaided    D        0.818    0.819      0.999            0.948       -0.00569\n5 Unaided    E        0.748    0.753      0.993            1.10         0.0719 \n6 Unaided    F        0.695    0.751      0.925            0.802        0.336  \n\nescala2 <- escala |>\n  select(assessment, rater, acuracia) \nescala3 <- escala2 |>\n  pivot_wider(1, names_from = assessment, values_from = acuracia)\n\nTeste T para amostras pareadas/dependentes\n\nattach(escala3)\nt_escala <- t.test(Aided1, Unaided,\n       paired = TRUE, var.equal = FALSE)\nvar.test(Aided1, Unaided)\n\n\n    F test to compare two variances\n\ndata:  Aided1 and Unaided\nF = 0.17041, num df = 9, denom df = 9, p-value = 0.01461\nalternative hypothesis: true ratio of variances is not equal to 1\n95 percent confidence interval:\n 0.04232677 0.68605885\nsample estimates:\nratio of variances \n         0.1704073 \n\nshapiro.test(Aided1)\n\n\n    Shapiro-Wilk normality test\n\ndata:  Aided1\nW = 0.92775, p-value = 0.4261\n\nshapiro.test(Unaided)\n\n\n    Shapiro-Wilk normality test\n\ndata:  Unaided\nW = 0.87462, p-value = 0.1131\n\nreport(t_escala)\n\nEffect sizes were labelled following Cohen's (1988) recommendations.\n\nThe Paired t-test testing the difference between Aided1 and Unaided (mean\ndifference = 0.18) suggests that the effect is positive, statistically\nsignificant, and large (difference = 0.18, 95% CI [0.11, 0.26], t(9) = 5.94, p\n< .001; Cohen's d = 1.88, 95% CI [0.81, 2.91])\n\nwilcox.test(Aided1, Unaided)\n\n\n    Wilcoxon rank sum exact test\n\ndata:  Aided1 and Unaided\nW = 100, p-value = 1.083e-05\nalternative hypothesis: true location shift is not equal to 0\n\nescala |>\n  ggplot(aes(assessment, precisao))+\n  geom_boxplot()\n\n\n\n\n\nescala |>\n  ggplot(aes())"
  },
  {
    "objectID": "Aula6.html",
    "href": "Aula6.html",
    "title": "Scatter plot",
    "section": "",
    "text": "Scatter plot\nDuas variáveis relacionadas.\n\nlibrary(tidyverse)\nlibrary(readxl)\nfung <- read_excel(\"dados-diversos.xlsx\",\n                   \"fungicida_campo\")\n\na função size dentro do ggplot, muda o tamanho dos pontos.\n\nfung |> \n  ggplot(aes(trat, sev)) +\n  geom_jitter(width = 0.1, color = \"gray\") + stat_summary(fun.data = mean_se, color = \"black\")\n\n\n\n\nGráfico de regressão linear, mas só colocando a reta, sem calcular os parâmetros\n\nfung |>\n   ggplot(aes(sev, yld))+\n  geom_point(alpha = 0.5, color = \"gray50\")+\n  scale_color_binned()+\n  geom_smooth(method = \"lm\",\n              se = FALSE,\n              color = \"black\",\n              linetype = \"dashed\",\n              size = 1)\n\n\n\n\n\nmilho <- read_excel(\"dados-diversos.xlsx\",\n                    \"milho\")\n\n\nmilho |>\n   ggplot(aes(method, yield, color = method))+\n     geom_point()+\n  facet_wrap(~hybrid)\n\n\n\nmilho |>\n   ggplot(aes(method, yield, color = method))+\n     geom_point()+\n  facet_grid(~hybrid)\n\n\n\n\n#Fazendo um histograma\n\ng1 <- milho |>\n   ggplot(aes(x= yield))+\n     geom_histogram(bins = 10, color = \"gray40\", fill = \"gray80\")+\n  theme_classic()\n\ng2 <- milho |>\n   ggplot(aes(x= index))+\n     geom_histogram(bins = 10, color = \"gray40\", fill = \"gray80\")+\n  theme_classic()\n\nmilho |>\n   ggplot(aes(x= index))+\n     geom_density()\n\n\n\nlibrary(patchwork)\n(g1 | g2)+\n  plot_annotation(tag_levels = 'A', title= 'Gráfico Milho')\n\n\n\n ggsave(\"figs/histograma.png\",\n          bg = \"white\", width = 6, height= 4)\n\n\ninsect <- read_excel(\"dados-diversos.xlsx\", \"mortalidade\")\n\ninsect |>\n  pivot_longer(2:3,\n               names_to = \"status\",\n               values_to = \"value\") |>\n  ggplot(aes(inseticida, value, \n             fill = status))+\n  geom_col()"
  },
  {
    "objectID": "Aula7.html",
    "href": "Aula7.html",
    "title": "Histograma",
    "section": "",
    "text": "library(tidyverse)\nlibrary(readxl)\nmofo <- read_excel(\"dados-diversos.xlsx\", \"mofo\")\n\n\nmofo |>\n   ggplot(aes(treat, yld))+\n  geom_col()+\n  facet_wrap(~study)\n\n\n\n\n\nhist <- mofo |>\n  ggplot(aes(x= scl))+\n     geom_histogram(bins = 10, color = \"gray40\", fill = \"gray80\")\n\ncriando uma variavel\n\nmofo2 <- mofo |>\n   mutate(scl2 = sqrt(scl))\n\n\nhist2 <- mofo2 |>\n  ggplot(aes(x= scl2))+\n     geom_histogram(bins = 10, color = \"gray40\", fill = \"gray80\")\n\n\nlibrary(patchwork)\n(hist | hist2) \n\n\n\n\narrange reordena, mutate cira uma variavel nova MUTATE CLASSIFICA\n\nsurvey <-\n  read_excel(\"dados-diversos.xlsx\", \"survey\")\n\nsurvey |>\n   filter(state == \"RS\") |>\n  count(species, residue) |>\n  arrange(n) |>\n  rename(res = residue) |>\n  mutate(n_class = case_when( n < 30 ~ \"baixa\",\n         TRUE ~ \"Alta\"))\n\n# A tibble: 4 × 4\n  species res         n n_class\n  <chr>   <chr>   <int> <chr>  \n1 Fspp    corn       22 baixa  \n2 Fspp    soybean    26 baixa  \n3 Fgra    corn      147 Alta   \n4 Fgra    soybean   255 Alta"
  },
  {
    "objectID": "Aula10.html",
    "href": "Aula10.html",
    "title": "Anova 1 fator",
    "section": "",
    "text": "Quando se trabalha com 2 tratamentos, os passos para seguir são: Teste de normalidade - shapiro.test, seguido de var.test, que se o p-valor der menor que 0,05 realiza testes não paramétricos (Mann-Whitney e Wilcoxon). Caso o p-vallor seja maior que 0,05, realiza-se o t.test —-> var.equal = F.\n\n\nPergunta a ser resposndida: Há efeito da espécie no crescimento micelial?\n\nlibrary(readxl)\nlibrary(tidyverse)\nmicelial <- read_excel(\"dados-diversos.xlsx\", \"micelial\")\nhead(micelial)\n\n# A tibble: 6 × 3\n  especie   rep   tcm\n  <chr>   <dbl> <dbl>\n1 Fasi        1  1.5 \n2 Fasi        2  1.59\n3 Fasi        3  1.52\n4 Fasi        4  1.52\n5 Fasi        5  1.24\n6 Fasi        6  1.29\n\n\n\nmicelial |>\n  ggplot(aes(especie, tcm))+\n  geom_boxplot()\n\n\n\n\n###Usando AOV\nCria um novo modelo para atribuir a função aov() contendo os argumentos (tcm em função de espécie). Depois disso, resume o novo modelo criado com a função summary.\n\naov1 <- aov(tcm ~ especie, data = micelial)\nsummary(aov1)\n\n            Df Sum Sq Mean Sq F value Pr(>F)\nespecie      4 0.4692 0.11729   1.983  0.117\nResiduals   37 2.1885 0.05915               \n\n\nConclusão: Nesse conjunto de dados, não há diferença na media micelial (não há efeito significativo da espécie sobre o cresc. micelial).\n\n\nDepois de fazer a anova, testa-se as premissas. É mais importante os dados serem homogeneos do que normais. Testando as premissas da anova - de normalidade e homocedasticidade do modelo: Para testar as premissas, é necessário instalar e carregar o pacote performance e o pacote DHARMa. O pacote performance permite checar as premissas (check_), já o pacote DHARMA ((Distributed Hierarchical Accumulation of Residuals for Generalized Linear Models in R) é para visualizar os dados pelo diagnóstico do resíduo (O pacote DHARMa permite faz uma comparação dos resíduos simulados, que são gerados pelo pacote, com os resíduos observados) e ver graficamente quando a distribuição dos dados não é normal e/ou quando há variação heterocedástica.\n\nlibrary(performance)\ncheck_heteroscedasticity(aov1)\n\nOK: Error variance appears to be homoscedastic (p = 0.175).\n\ncheck_normality(aov1)\n\nOK: residuals appear as normally distributed (p = 0.074).\n\nlibrary(DHARMa)\nhist (aov1$residuals)\n\n\n\nqqnorm(aov1$residuals)\nqqline(aov1$residuals)\n\n\n\nplot(simulateResiduals(aov1))\n\n\n\nshapiro.test(aov1$residuals)\n\n\n    Shapiro-Wilk normality test\n\ndata:  aov1$residuals\nW = 0.95101, p-value = 0.07022\n\n\n\n\n\n\nAbrir um conjunto de dados que está no R chamado InsectSprays.\n\ninsects <- as_tibble(InsectSprays) |>\n  select(spray, count)\n\n\ninsects |>\n  ggplot(aes(spray, count))+\n  geom_boxplot()\n\n\n\n\nRodando o modelo de anova: como os dados, aparentemente - pelo visual do gráfico - apresentaram-se não paramétricos, roda-se a anova e testa-se as premissas para confirmação.\n\naov2 <- aov(count ~ spray, data = insects)\nsummary(aov2)\n\n            Df Sum Sq Mean Sq F value Pr(>F)    \nspray        5   2669   533.8    34.7 <2e-16 ***\nResiduals   66   1015    15.4                   \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\ncheck_normality(aov2)\n\nWarning: Non-normality of residuals detected (p = 0.022).\n\ncheck_heteroscedasticity(aov2)\n\nWarning: Heteroscedasticity (non-constant error variance) detected (p < .001).\n\n\nInterpretação: dados não são normais e homogeneos.\n\n\nQuando se tem dados não paramétricos, tem-se 3 alternativas - transformar os dados (raiz quadrada, log, etc); usar testes não paramétricos (Kruskal) ou usar modelos lineares generalizados (melhor opção).\n\nTransformar os dados para normalizar: Usa-se a raiz quadrada para tentar noprmalizar e tornar os dados normais e homogenos. Pode-se também tentar o log da variável resposta + 0.5.\n\n\naov2 <- aov(sqrt(count) ~ spray, data = insects)\nsummary(aov2)\n\n            Df Sum Sq Mean Sq F value Pr(>F)    \nspray        5  88.44  17.688    44.8 <2e-16 ***\nResiduals   66  26.06   0.395                   \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\ncheck_normality(aov2)\n\nOK: residuals appear as normally distributed (p = 0.681).\n\ncheck_heteroscedasticity(aov2)\n\nOK: Error variance appears to be homoscedastic (p = 0.854).\n\n\n\nSe não normalizar e os dados ainda forem heterogenos, usa-se testes não paramétricos. Tem 2 opções de teste Kruskal. Para usar essa opção, é necessário baixar e carregar o pacote agricolae.\n\n\nkruskal.test(count ~ spray, data = insects)\n\n\n    Kruskal-Wallis rank sum test\n\ndata:  count by spray\nKruskal-Wallis chi-squared = 54.691, df = 5, p-value = 1.511e-10\n\nlibrary(agricolae)\nkruskal(insects$count, insects$spray, \n        console = TRUE) #separa por grupos.\n\n\nStudy: insects$count ~ insects$spray\nKruskal-Wallis test's\nTies or no Ties\n\nCritical Value: 54.69134\nDegrees of freedom: 5\nPvalue Chisq  : 1.510845e-10 \n\ninsects$spray,  means of the ranks\n\n  insects.count  r\nA      52.16667 12\nB      54.83333 12\nC      11.45833 12\nD      25.58333 12\nE      19.33333 12\nF      55.62500 12\n\nPost Hoc Analysis\n\nt-Student: 1.996564\nAlpha    : 0.05\nMinimum Significant Difference: 8.462804 \n\nTreatments with the same letter are not significantly different.\n\n  insects$count groups\nF      55.62500      a\nB      54.83333      a\nA      52.16667      a\nD      25.58333      b\nE      19.33333     bc\nC      11.45833      c\n\n\n\n\nO pacote emmeans (“estimated marginal means”, ou médias marginais estimadas) é usado para realizar testes de comparação de médias entre grupos, ajustando para outros fatores importantes que podem influenciar as médias. O pacote é particularmente útil em modelos lineares generalizados (GLM).\nFunção emmeans - tirar a média da variável inseticida: Para dar o valor original da média e não o valor transformado, usa-se a função type = response. A função pwpm gera uma tabela de comparação das médias e cld é uma função que serve para gerar os números que diferenciam os grupos de médias.\n\naov2 <- aov(count ~ spray, data = insects)\nsummary(aov2)\n\n            Df Sum Sq Mean Sq F value Pr(>F)    \nspray        5   2669   533.8    34.7 <2e-16 ***\nResiduals   66   1015    15.4                   \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\ncheck_normality(aov2)\n\nWarning: Non-normality of residuals detected (p = 0.022).\n\ncheck_heteroscedasticity(aov2)\n\nWarning: Heteroscedasticity (non-constant error variance) detected (p < .001).\n\nlibrary(emmeans)\naov2 <- means <- emmeans(aov2, ~ spray,\n                         type = \"response\")\n\n\nGLM A terceira opção é a geração de modelos lineares generalizados. Para publicação de artigos, essa é a opção mais aconselhável, é mais elegante do que transformar os dados. Para visualizar, pode usar o pacote Dharma e puxar um plot.\n\n\nglm1 <- glm(count ~spray,\n             data = insects,\n            \n             family = poisson(link = \"identity\"))\nplot(simulateResiduals(glm1))\n\n\n\nsummary(glm1)\n\n\nCall:\nglm(formula = count ~ spray, family = poisson(link = \"identity\"), \n    data = insects)\n\nDeviance Residuals: \n    Min       1Q   Median       3Q      Max  \n-2.3852  -0.8876  -0.1482   0.6063   2.6922  \n\nCoefficients:\n            Estimate Std. Error z value Pr(>|z|)    \n(Intercept)  14.5000     1.0992  13.191  < 2e-16 ***\nsprayB        0.8333     1.5767   0.529    0.597    \nsprayC      -12.4167     1.1756 -10.562  < 2e-16 ***\nsprayD       -9.5833     1.2720  -7.534 4.92e-14 ***\nsprayE      -11.0000     1.2247  -8.981  < 2e-16 ***\nsprayF        2.1667     1.6116   1.344    0.179    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for poisson family taken to be 1)\n\n    Null deviance: 409.041  on 71  degrees of freedom\nResidual deviance:  98.329  on 66  degrees of freedom\nAIC: 376.59\n\nNumber of Fisher Scoring iterations: 3"
  },
  {
    "objectID": "Aula11.html",
    "href": "Aula11.html",
    "title": "Anova 2 fatores",
    "section": "",
    "text": "Carregar dados : fungicida_vaso: 2 fungicidas x 2 doses (quando é duas doses fica como fator qualitativo).\nn de repetições: 5\nn-sp : numero de espigas\ndis-sp: numero de espigas doentes\n\nlibrary (tidyverse)\nlibrary(tidyverse)\nlibrary(readxl)\nlibrary(ggplot2)\nfung <- read_excel(\"dados-diversos.xlsx\", \"fungicida_vaso\")\n\nCriando a variável percentual de espigas\nmutate pra criar uma outra coluna para incidência\n\nfung2 <- fung |>\n  mutate(inc = dis_sp / n_sp * 100)\n\ncriando um gráfico para visualizar\ncom esse grafico conseguimos visualizar que provavelmente tem interação fungicida ~ dose\n\nfung2 |>\nggplot(aes(x= treat, y =inc))+\n  geom_jitter(width = 0.1)+\n  facet_wrap(~dose)\n\n\n\n\nanova: considerando dois fatores qualitativos\ninterpretando anova: todos as fontes de variação foram significativas\n\nm1 <- aov(inc ~ treat*dose, data = fung2)\nsummary(m1)\n\n            Df Sum Sq Mean Sq F value   Pr(>F)    \ntreat        1  919.5   919.5   24.31 0.000151 ***\ndose         1  920.9   920.9   24.34 0.000150 ***\ntreat:dose   1  747.7   747.7   19.76 0.000407 ***\nResiduals   16  605.3    37.8                     \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nconferindo premissas com pacote performance\ndados não foram homogêneos e nem homocedasticidade\n\nlibrary(performance)\ncheck_normality(m1)\n\nWarning: Non-normality of residuals detected (p = 0.018).\n\ncheck_heteroscedasticity(m1)\n\nWarning: Heteroscedasticity (non-constant error variance) detected (p < .001).\n\nlibrary(DHARMa)\nplot(simulateResiduals(m1))\n\n\n\n\ntranformando dados > Que transformação usa pra percentagem > log +0.5\nconseguiu ter homcedasticidade\ncomo a normalidade deu 0.05 consegue ainda fazer, o que é mais importante é a homocedasticidade\n\nm1 <- aov(log(inc+0.5) ~ treat*dose, data = fung2)\nsummary(m1)\n\n            Df Sum Sq Mean Sq F value  Pr(>F)   \ntreat        1 12.928  12.928  13.980 0.00179 **\ndose         1  5.663   5.663   6.124 0.02491 * \ntreat:dose   1  5.668   5.668   6.129 0.02486 * \nResiduals   16 14.796   0.925                   \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\ncheck_normality(m1)\n\nWarning: Non-normality of residuals detected (p = 0.050).\n\ncheck_heteroscedasticity(m1)\n\nOK: Error variance appears to be homoscedastic (p = 0.180).\n\nplot(simulateResiduals(m1))\n\n\n\nlibrary(emmeans)#comparando médias, médias pra cada interação\nmeans_m1 <- emmeans(m1, ~ treat | dose,\n                    type= \"response\")\nmeans_m1\n\ndose = 0.5:\n treat        response     SE df lower.CL upper.CL\n Ionic liquid    27.05 11.847 16   10.570    68.05\n Tebuconazole     1.21  0.737 16    0.188     3.76\n\ndose = 2.0:\n treat        response     SE df lower.CL upper.CL\n Ionic liquid     3.10  1.412 16    1.065     7.77\n Tebuconazole     1.42  0.925 16    0.194     4.83\n\nConfidence level used: 0.95 \nIntervals are back-transformed from the log(mu + 0.5) scale \n\nlibrary(multcompView)\nlibrary(multcomp)\ncld(means_m1)\n\ndose = 0.5:\n treat        response     SE df lower.CL upper.CL .group\n Tebuconazole     1.21  0.737 16    0.188     3.76  1    \n Ionic liquid    27.05 11.847 16   10.570    68.05   2   \n\ndose = 2.0:\n treat        response     SE df lower.CL upper.CL .group\n Tebuconazole     1.42  0.925 16    0.194     4.83  1    \n Ionic liquid     3.10  1.412 16    1.065     7.77  1    \n\nConfidence level used: 0.95 \nIntervals are back-transformed from the log(mu + 0.5) scale \nTests are performed on the log scale \nsignificance level used: alpha = 0.05 \nNOTE: If two or more means share the same grouping letter,\n      then we cannot show them to be different.\n      But we also did not show them to be the same. \n\n#agora ao contrario\nmeans_m1 <- emmeans(m1, ~ dose | treat,\n                    type= \"response\")\nmeans_m1\n\ntreat = Ionic liquid:\n dose response     SE df lower.CL upper.CL\n  0.5    27.05 11.847 16   10.570    68.05\n  2.0     3.10  1.412 16    1.065     7.77\n\ntreat = Tebuconazole:\n dose response     SE df lower.CL upper.CL\n  0.5     1.21  0.737 16    0.188     3.76\n  2.0     1.42  0.925 16    0.194     4.83\n\nConfidence level used: 0.95 \nIntervals are back-transformed from the log(mu + 0.5) scale \n\nlibrary(multcompView)\nlibrary(multcomp)\ncld(means_m1)\n\ntreat = Ionic liquid:\n dose response     SE df lower.CL upper.CL .group\n  2.0     3.10  1.412 16    1.065     7.77  1    \n  0.5    27.05 11.847 16   10.570    68.05   2   \n\ntreat = Tebuconazole:\n dose response     SE df lower.CL upper.CL .group\n  0.5     1.21  0.737 16    0.188     3.76  1    \n  2.0     1.42  0.925 16    0.194     4.83  1    \n\nConfidence level used: 0.95 \nIntervals are back-transformed from the log(mu + 0.5) scale \nTests are performed on the log scale \nsignificance level used: alpha = 0.05 \nNOTE: If two or more means share the same grouping letter,\n      then we cannot show them to be different.\n      But we also did not show them to be the same. \n\nlibrary(agricolae)\ncv.model(m1)\n\n[1] 65.04818"
  },
  {
    "objectID": "Aula11.html#anova-com-dois-fatores-para-dados-sem-normalidade",
    "href": "Aula11.html#anova-com-dois-fatores-para-dados-sem-normalidade",
    "title": "Anova 2 fatores",
    "section": "Anova com dois fatores para dados sem normalidade",
    "text": "Anova com dois fatores para dados sem normalidade\n\nlibrary(readxl)\nlibrary(tidyverse)\nmicelial <- read_excel(\"dados-diversos.xlsx\", \"fungicida_vaso\")\nmicelial2 <- micelial |>\n  mutate(inc = inf_seeds/n_seeds*100, rank_inc = rank(inc)) #transforma os dados da variavel resposta (inc)\n\nrank_anova <- aov(rank_inc ~ treat*dose, data = micelial2)\nsummary(rank_anova)  \n\n            Df Sum Sq Mean Sq F value  Pr(>F)   \ntreat        1 220.00  220.00  14.204 0.00168 **\ndose         1 105.34  105.34   6.801 0.01904 * \ntreat:dose   1  80.34   80.34   5.187 0.03684 * \nResiduals   16 247.82   15.49                   \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nlibrary(emmeans)\nmeans_rank <- emmeans(rank_anova, ~ treat | dose)\nlibrary(multcompView)\nlibrary(multcomp)\ncld(means_rank)  #não usar as médias daqui, colocar médias reais e só usar a separação das médias . Se não der siginificativo a interação vc pode usar a anova sozinha, pra cada fator ou faz kruskal normal que separa pra um fator. \n\ndose = 0.5:\n treat        emmean   SE df lower.CL upper.CL .group\n Tebuconazole   6.90 1.76 16     3.17     10.6  1    \n Ionic liquid  18.00 1.76 16    14.27     21.7   2   \n\ndose = 2.0:\n treat        emmean   SE df lower.CL upper.CL .group\n Tebuconazole   6.75 1.97 16     2.58     10.9  1    \n Ionic liquid   9.75 1.61 16     6.34     13.2  1    \n\nConfidence level used: 0.95 \nsignificance level used: alpha = 0.05 \nNOTE: If two or more means share the same grouping letter,\n      then we cannot show them to be different.\n      But we also did not show them to be the same."
  },
  {
    "objectID": "Aula11.html#fazendo-outra-coisa",
    "href": "Aula11.html#fazendo-outra-coisa",
    "title": "Anova 2 fatores",
    "section": "fazendo outra coisa",
    "text": "fazendo outra coisa\n\nlibrary(MASS)\n\ninsects <- InsectSprays\n\nb <- boxcox(lm(InsectSprays$count+0.1 ~1)) #depende da tabelinha do lang vc sabe qual é a transformação pra ver quan é o lambda\n\n\n\nlambda  <- b$x[which.max(b$y)]\nlambda\n\n[1] 0.4242424\n\ninsects$count2 <- (insects$count ^ lambda - 1) / lambda\n\ninsects$count2\n\n [1]  3.903635  3.024469  6.043993  4.864268  4.864268  4.407118  3.903635\n [8]  6.557185  5.484274  6.043993  4.864268  4.640760  4.161975  5.484274\n[15]  6.219699  4.161975  5.285168  4.864268  5.484274  5.484274  5.863153\n[22]  6.219699  3.024469  4.640760 -2.357143  0.000000  3.024469  0.805831\n[29]  1.399509  0.000000  0.805831  0.000000  1.399509 -2.357143  0.000000\n[36]  1.887150  1.399509  2.308577  4.407118  2.683787  1.887150  1.399509\n[43]  2.308577  2.308577  2.308577  2.308577  0.805831  1.887150  1.399509\n[50]  2.308577  1.399509  2.308577  1.399509  2.683787  0.000000  0.000000\n[57]  1.399509  0.805831  2.683787  1.887150  4.161975  3.629951  5.078760\n[64]  6.390651  5.078760  5.285168  4.640760  3.903635  7.033117  7.033117\n[71]  6.719601  4.640760\n\nhist(insects$count)\n\n\n\n#quando eu transformar os dados pra ver se tem normalidade ou não eu tenho que além de fazer o teste de heterocedasticidade visualizar a normalidade dos gráficos.\n\n\n#no pacote agricolae colocar um ponto de interrogação pra ver qual o teste para separar as médias."
  },
  {
    "objectID": "Aula12.html",
    "href": "Aula12.html",
    "title": "Anova em DBC",
    "section": "",
    "text": "library(readxl)\nlibrary(tidyverse)\n\nfungicidas <- \nread_excel(\"dados-diversos.xlsx\", \"fungicida_campo\")\n\nmodelo com anova com bloco severidade em função do tratamento + bloco mesmo quando o bloco não é significativo você apresenta ele\n\naov_fung <- aov(sev ~ trat + rep, data = fungicidas)\nsummary(aov_fung)\n\n            Df Sum Sq Mean Sq F value Pr(>F)    \ntrat         7   7135  1019.3 287.661 <2e-16 ***\nrep          1     19    18.6   5.239 0.0316 *  \nResiduals   23     81     3.5                   \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nVerificar premissas\nA média estimada é diferente da aritmética, de acordo com o modelo.\n\nlibrary(performance)\nlibrary(DHARMa)\ncheck_normality(aov_fung)\n\nOK: residuals appear as normally distributed (p = 0.230).\n\ncheck_heteroscedasticity(aov_fung)\n\nOK: Error variance appears to be homoscedastic (p = 0.484).\n\nplot(simulateResiduals(aov_fung))\n\n\n\nlibrary(emmeans)\n\nmeans_fung <- emmeans(aov_fung, ~trat)\nlibrary(multcomp)\nlibrary(multcompView)\n\ncld(means_fung)\n\n trat       emmean    SE df lower.CL upper.CL .group\n G            29.2 0.941 23     27.3     31.2  1    \n B            29.5 0.941 23     27.6     31.4  1    \n E            30.1 0.941 23     28.2     32.1  1    \n C            30.4 0.941 23     28.4     32.3  1    \n A            30.4 0.941 23     28.4     32.3  1    \n D            31.5 0.941 23     29.6     33.4  12   \n F            35.5 0.941 23     33.6     37.4   2   \n testemunha   75.8 0.941 23     73.8     77.7    3  \n\nConfidence level used: 0.95 \nP value adjustment: tukey method for comparing a family of 8 estimates \nsignificance level used: alpha = 0.05 \nNOTE: If two or more means share the same grouping letter,\n      then we cannot show them to be different.\n      But we also did not show them to be the same. \n\nplot(means_fung)+\n  coord_flip()"
  },
  {
    "objectID": "Aula13.html",
    "href": "Aula13.html",
    "title": "Regressão",
    "section": "",
    "text": "Quando os fatores do tratamento é quantitativo nós fazemos análise de regressão.\ncoeficiente angular: da linha do gráfico da regressão.\na pergunta: a uma tendencia em declinar ou aumentar?\nqueremos saber se a linha é diferente do angulo zero, que seria reta.\nGeom_smooth coloca a linha.\n\nlibrary(readxl)\nlibrary(tidyverse)\nlibrary(ggplot2)\n\nestande <- read_excel(\"dados-diversos.xlsx\", \"estande\")\n\nestande |>\n  ggplot(aes(trat, nplants))+\n  geom_point()+\n  facet_wrap(~exp)+\n  ylim(0,max(estande$nplants))+\n  geom_smooth(se = F, method= \"lm\")#para a colocar a linha e lm para deixar em padrão linear.\n\n\n\n\n3\n\nexp1 <- estande |>\n  filter(exp == 1) \nm1 <- lm(nplants ~ trat, data = exp1)#nplants é a resposta em função do trat\nsummary(m1)\n\n\nCall:\nlm(formula = nplants ~ trat, data = exp1)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-25.500  -6.532   1.758   8.573  27.226 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  52.5000     4.2044  12.487 1.84e-11 ***\ntrat         -0.2419     0.1859  -1.301    0.207    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 15 on 22 degrees of freedom\nMultiple R-squared:  0.07148,   Adjusted R-squared:  0.02928 \nF-statistic: 1.694 on 1 and 22 DF,  p-value: 0.2066\n\nexp2 <- estande |>\n  filter(exp == 2) \nm2 <- lm(nplants ~ trat, data = exp2)#nplants é a resposta em função do trat\nsummary(m2)\n\n\nCall:\nlm(formula = nplants ~ trat, data = exp2)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-25.7816  -7.7150   0.5653   8.1929  19.2184 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  60.9857     3.6304  16.798 4.93e-14 ***\ntrat         -0.7007     0.1605  -4.365 0.000247 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 12.95 on 22 degrees of freedom\nMultiple R-squared:  0.4641,    Adjusted R-squared:  0.4398 \nF-statistic: 19.05 on 1 and 22 DF,  p-value: 0.0002473\n\nexp3 <- estande |>\n  filter(exp == 3) \nm3 <- lm(nplants ~ trat, data = exp3)#nplants é a resposta em função do trat\nsummary(m3)\n\n\nCall:\nlm(formula = nplants ~ trat, data = exp3)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-26.5887  -3.9597   0.7177   5.5806  19.8952 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  95.7500     2.9529  32.425  < 2e-16 ***\ntrat         -0.7634     0.1306  -5.847 6.97e-06 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 10.53 on 22 degrees of freedom\nMultiple R-squared:  0.6085,    Adjusted R-squared:  0.5907 \nF-statistic: 34.19 on 1 and 22 DF,  p-value: 6.968e-06\n\nlibrary(report)\nreport(m3)\n\nWe fitted a linear model (estimated using OLS) to predict nplants with trat\n(formula: nplants ~ trat). The model explains a statistically significant and\nsubstantial proportion of variance (R2 = 0.61, F(1, 22) = 34.19, p < .001, adj.\nR2 = 0.59). The model's intercept, corresponding to trat = 0, is at 95.75 (95%\nCI [89.63, 101.87], t(22) = 32.43, p < .001). Within this model:\n\n  - The effect of trat is statistically significant and negative (beta = -0.76,\n95% CI [-1.03, -0.49], t(22) = -5.85, p < .001; Std. beta = -0.78, 95% CI\n[-1.06, -0.50])\n\nStandardized parameters were obtained by fitting the model on a standardized\nversion of the dataset. 95% Confidence Intervals (CIs) and p-values were\ncomputed using a Wald t-distribution approximation.\n\ng1 <- exp1 |>\n  ggplot(aes(trat, nplants))+\n  geom_point()+\n  ylim(0, max(estande$nplants))+\n  geom_smooth(method = \"lm\", se = F)+\n  annotate(geom = \"text\", x = 24, y= 70, label = \"y = 52.5 - 0.24x\")\n\ng2 <- exp2 |>\n  ggplot(aes(trat, nplants))+\n  geom_point()+\n  ylim(0, max(estande$nplants))+\n  geom_smooth(method = \"lm\", se = F)+\n  annotate(geom = \"text\", x = 24, y= 70, label = \"y = 60 - 0.7x\")\n\ng3 <- exp3 |>\n  ggplot(aes(trat, nplants))+\n  geom_point()+\n  ylim(0, max(estande$nplants))+\n  geom_smooth(method = \"lm\", se = F)+\n  annotate(geom = \"text\", x = 24, y= 70, label = \"y = 95 - 0.7x\")\n\n\nlibrary(patchwork)\ng1 | g2 | g3\n\n\n\n\nOs dois métodos são certos, você pode usar uma abordagem ou outra.\nNo segundo método o experimento é considerado um fator aleatório. e considera o valor dos 3 experimentos juntos. Porém é mais recomendado quando tem mais repetições, 3 é pouco.\n\nlibrary(lme4)#modelo misto porque tem fator fixo e aleatório, no outro regressão só tem fixo, o experimento é o componente aleatório. Vai juntar os 3 experimentos em um modelo só.\nmix <- lmer(nplants ~ trat + (trat |exp), \n            data = estande)\nsummary(mix)\n\nLinear mixed model fit by REML ['lmerMod']\nFormula: nplants ~ trat + (trat | exp)\n   Data: estande\n\nREML criterion at convergence: 580.8\n\nScaled residuals: \n    Min      1Q  Median      3Q     Max \n-2.0988 -0.6091  0.1722  0.6360  1.9963 \n\nRandom effects:\n Groups   Name        Variance  Std.Dev. Corr \n exp      (Intercept) 510.68405 22.5983       \n          trat          0.05516  0.2349  -0.82\n Residual             167.91303 12.9581       \nNumber of obs: 72, groups:  exp, 3\n\nFixed effects:\n            Estimate Std. Error t value\n(Intercept)  69.7452    13.2146   5.278\ntrat         -0.5687     0.1643  -3.462\n\nCorrelation of Fixed Effects:\n     (Intr)\ntrat -0.731\noptimizer (nloptwrap) convergence code: 0 (OK)\nModel failed to converge with max|grad| = 0.00274249 (tol = 0.002, component 1)\n\nlibrary(car)\nAnova(mix)#aqui da o P-valor, calcula a média do slop dos 3.\n\nAnalysis of Deviance Table (Type II Wald chisquare tests)\n\nResponse: nplants\n      Chisq Df Pr(>Chisq)    \ntrat 11.985  1  0.0005362 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nmodelo glm\nmodelo linear é um caso especial de glm, que é a familia gaussian.\nnplantas= numerica discreta, usa familia poisson\nnumerica continua = familia gaussian\nFizemos o ajusto modelo aos dados.\n\nglm1 <- glm(nplants ~ trat, family = \"gaussian\",\n            data=exp3)\nsummary(glm1)\n\n\nCall:\nglm(formula = nplants ~ trat, family = \"gaussian\", data = exp3)\n\nDeviance Residuals: \n     Min        1Q    Median        3Q       Max  \n-26.5887   -3.9597    0.7177    5.5806   19.8952  \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  95.7500     2.9529  32.425  < 2e-16 ***\ntrat         -0.7634     0.1306  -5.847 6.97e-06 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for gaussian family taken to be 110.9787)\n\n    Null deviance: 6235.8  on 23  degrees of freedom\nResidual deviance: 2441.5  on 22  degrees of freedom\nAIC: 185.04\n\nNumber of Fisher Scoring iterations: 2\n\nglm2 <- glm(nplants ~ trat, family = poisson(link = \"log\"),\n            data=exp3)\n\nAIC(glm1) # quanto menor o aic melhor o modelo\n\n[1] 185.0449\n\nAIC(glm2)  # esse modelo deu melhor porque deu menor.\n\n[1] 183.9324\n\nsummary(glm2)\n\n\nCall:\nglm(formula = nplants ~ trat, family = poisson(link = \"log\"), \n    data = exp3)\n\nDeviance Residuals: \n     Min        1Q    Median        3Q       Max  \n-2.94600  -0.46988   0.02453   0.61868   2.34657  \n\nCoefficients:\n             Estimate Std. Error z value Pr(>|z|)    \n(Intercept)  4.571590   0.029539 154.762  < 2e-16 ***\ntrat        -0.009965   0.001488  -6.697 2.13e-11 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for poisson family taken to be 1)\n\n    Null deviance: 77.906  on 23  degrees of freedom\nResidual deviance: 29.952  on 22  degrees of freedom\nAIC: 183.93\n\nNumber of Fisher Scoring iterations: 4"
  },
  {
    "objectID": "Aula14.html",
    "href": "Aula14.html",
    "title": "Regressão não-linear",
    "section": "",
    "text": "Linha quadrática ou sigmodial a linha não é reta., tem uma curvatura. pq tem mais um fator\ny=b1-b2x-cx²\nver se é quadratica ou não antes\nverificar os coeficientes\ne depois colocar no gráfico a formula\n\nlibrary(readxl)\nlibrary(tidyverse)\nlibrary(ggplot2)\n\nestande <- read_excel(\"dados-diversos.xlsx\", \"estande\")\n\nestande |>\n  ggplot(aes(trat, nplants))+\n  geom_point()+\n  facet_wrap(~exp)+\n  ylim(0,max(estande$nplants))+\n  geom_smooth(se = F)\n\n\n\n\n\nestande2 <- estande |>\n  filter(exp==2)|>\n  group_by(trat) |> #vai eliminar o bloco\n  summarise(mean_nplants = mean(nplants)) \n\n\n estande2 |>\n  ggplot(aes(trat, mean_nplants))+\n  geom_point()+\n # geom_line()+\n   geom_smooth(span=2, se=FALSE) #se vc colocar span= algo, vai deixando a linha menos curvada\n\n\n\n estande2 |>\n  ggplot(aes(trat, mean_nplants))+\n  geom_point()+\n# geom_line()+\n   geom_smooth(method= \"lm\", se=FALSE, formula = y ~poly(x,2), color=\"black\")+ #poly(x,2) já está transformando ao quadrado os valores\n   theme_minimal()+\n   annotate(geom=\"text\", x = 25, y = 70, label = \"y= 66.3 - 1777 + 0.0222x²\n            R-squared = 0.88\")\n\n\n\n\n\nestande2 <- estande2 |>\n  mutate(trat2 = trat^2)\n\nm1 <- lm(mean_nplants ~ trat, data = estande2)\nsummary(m1)\n\n\nCall:\nlm(formula = mean_nplants ~ trat, data = estande2)\n\nResiduals:\n     1      2      3      4      5      6 \n12.764 -2.134 -6.782 -3.327 -4.669  4.147 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  60.9857     4.5505  13.402 0.000179 ***\ntrat         -0.7007     0.2012  -3.483 0.025294 *  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 8.117 on 4 degrees of freedom\nMultiple R-squared:  0.752, Adjusted R-squared:   0.69 \nF-statistic: 12.13 on 1 and 4 DF,  p-value: 0.02529\n\nhist(m1$residuals)# r-squared: 0.69% da variaçao é explicado pela quantidade de inóculo assumindo o modelo linear\n\n\n\nm2 <- lm(mean_nplants ~ trat + trat2, data = estande2) #criando modelo quadrático\nsummary(m2)  # Equação ficaria \n\n\nCall:\nlm(formula = mean_nplants ~ trat + trat2, data = estande2)\n\nResiduals:\n      1       2       3       4       5       6 \n 7.4484 -4.4200 -6.4386  1.0739  3.0474 -0.7111 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept) 66.30156    4.70800  14.083 0.000776 ***\ntrat        -1.77720    0.62263  -2.854 0.064878 .  \ntrat2        0.02223    0.01242   1.790 0.171344    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 6.517 on 3 degrees of freedom\nMultiple R-squared:  0.8801,    Adjusted R-squared:  0.8001 \nF-statistic: 11.01 on 2 and 3 DF,  p-value: 0.04152\n\nhist(m2$residuals)\n\n\n\nAIC(m1,m2) #o que der menor é melhor \n\n   df      AIC\nm1  3 45.72200\nm2  4 43.36151"
  },
  {
    "objectID": "Aula16.html",
    "href": "Aula16.html",
    "title": "Criando mapas no R",
    "section": "",
    "text": "Primeiro passo é instalar os pacotes\n\nlibrary(tidyverse)\nlibrary(r4pde)\nsbr <- RustSoybean\n\nlibrary(rnaturalearth)\nlibrary(rnaturalearthhires)\n\nremotes::install_github(\"ropensci/rnaturalearthhires\")\n\nBRA <- ne_states(country = \"Brazil\", returnclass = \"sf\")\nMG <- BRA |> filter(name_en == \"Minas Gerais\")\n\n\nggplot(BRA) +\n  geom_sf(color =\"black\", fill= \"white\")+\n  geom_sf(data = MG, fill =\"green\", color = \"black\")+\n  geom_point(data = sbr, aes(longitude, latitude), alpha = 0.5)+ #o alpha é pra sobreposição de pontos por cor\n  theme_void()\n\n\n\n\n\nsbr2 <- sbr |>\n  separate(planting, into = c(\"year\", \"month\", \"day\"), sep = \"-\", remove = FALSE)\n\n\nBRA <- ne_states(country = \"Brazil\", returnclass = \"sf\")\nMG <- BRA |> filter(name_en == \"Minas Gerais\")\n\nlibrary(ggsn)\nlibrary(ggspatial)\n\nggplot(BRA) +\n  annotation_scale(location=\"br\")+\n  annotation_north_arrow(location =\"bl\")+\n  geom_sf(color =\"black\", fill= \"white\")+\n # geom_sf(data = MG, fill =\"green\", color = \"black\")+\n  geom_point(data = sbr2, aes(longitude, latitude, color = year, size = severity), alpha = 0.5)+ #o alpha é pra sobreposição de pontos por cor\n  theme_void()+\n  #facet_wrap(~year)+#pra separar um gráfico por ano, ou se tirar fica só as cores diferentes pra cada ano no mesmo mapa\n  geom_hline(yintercept = -23)+\n  labs(color = \"Plating Year\")+\n  theme(legend.position = \"right\")"
  },
  {
    "objectID": "boxcox.html",
    "href": "boxcox.html",
    "title": "Transformação box-Cox",
    "section": "",
    "text": "Transformação box-Cox\nTécnica utilizada na análise estatística para melhorar a adequação dos dados a pressupostos de normalidade e homogeneidade de variância.\nEssa transformação é aplicada a variáveis contínuas positivas que possuem assimetria ou heterogeneidade de variância. A transformação de Box-Cox é definida pela seguinte equação: y(lambda) = (x^lambda - 1) / lambda\nSe lambda < 0, é aplicada uma transformação inversa.\n\nlibrary(MASS)\ninsects <- InsectSprays\nb <- boxcox(lm(insects$count+0.1 ~1))\n\n\n\n\n\nlambda <- b$x[which.max(b$y)]\nlambda\n\n[1] 0.4242424\n\ninsects$count2 <-(insects$count ^ lambda - 1) / lambda\nhist(insects$count)\n\n\n\n\n\nhist(insects$count2)"
  },
  {
    "objectID": "Box plot.html",
    "href": "Box plot.html",
    "title": "Box plot",
    "section": "",
    "text": "O boxplot ou diagrama de caixa é uma ferramenta gráfica que permite visualizar a distribuição e valores discrepantes (outliers) dos dados, fornecendo assim um meio complementar para desenvolver uma perspectiva sobre o caráter dos dados. \n\nlibrary(tidyverse)\nlibrary(readxl)\nmg <- read_excel(\"dados-diversos.xlsx\")\n\n\n\nfunção geom-jitter separa os pontos, diferente do geom_point que sobrepõem, e width é a largura entre os pontos scale_y_continuous > pra definir a escala do y\n\nlibrary(ggplot2)\npbox <- mg |>\n  ggplot(aes(trat,comp))+\n  geom_boxplot(outlier.color = NA, fill =\"orange\", \n               size = 0.5, width = 0.4) +\n  geom_jitter(width = 0.1, \n              height = 0, \n              size = 2,\n              color = \"black\") +\n  scale_y_continuous(limits = c(5,20),\n                     n.breaks = 10)+\n  labs(x = NULL, y = \"Lesion size (mm)\", title= \"\",\n       subtitle= \"\", caption = \"\")+\n  theme_minimal()\npbox\n\n\n\n  ggsave(\"figs/plot2.png\",  bg = \"white\")\n  dir.create(\"figs\")"
  },
  {
    "objectID": "Rstudio.html",
    "href": "Rstudio.html",
    "title": "RStudio",
    "section": "",
    "text": "RStudio é um software livre de ambiente de desenvolvimento integrado para R, uma linguagem de programação para gráficos e cálculos estatísticos.\nTodos os script disponibilidados neste site foram criados utilizando o Rstudio.\nPara fazer o dowlnoad clique aqui."
  },
  {
    "objectID": "aula17.html",
    "href": "aula17.html",
    "title": "EC50",
    "section": "",
    "text": "library(gsheet)\nlibrary(tidyverse)\n\ndat <- gsheet2tbl(\"https://docs.google.com/spreadsheets/d/15pCj0zljvd-TGECe67OMt6sa21xO8BqUgv4d-kU8qi8/edit#gid=0\")\n\noptions(scipen=999)\ndat2 <- dat |> \n  select(-Isolate, -Population) |> \n  group_by(Code, Year, Dose) |> \n  summarise(GC_mean = mean(GC)) \n  \n\nFGT152 <- dat2 |> \n  filter(Code == \"FGT152\")\n\nFGT152 |> \n  ggplot(aes(factor(Dose), GC_mean))+\n  geom_point()+\n  geom_line()\n\n\n\ndat2 |> \n   ggplot(aes(factor(Dose), GC_mean))+\n  geom_point()+\n  geom_line()+\n  facet_wrap(~Code)"
  },
  {
    "objectID": "aula17.html#ec50-com-pacote-drm",
    "href": "aula17.html#ec50-com-pacote-drm",
    "title": "EC50",
    "section": "EC50 com pacote DRM",
    "text": "EC50 com pacote DRM\n\nlibrary(drc)\ndrc1 <- drm(GC_mean ~ Dose, data = FGT152,\n    fct = LL.3())\nAIC(drc1)\n\n[1] 33.60846\n\nsummary(drc1)\n\n\nModel fitted: Log-logistic (ED50 as parameter) with lower limit at 0 (3 parms)\n\nParameter estimates:\n\n               Estimate Std. Error t-value     p-value    \nb:(Intercept)  0.401905   0.053427  7.5225    0.001672 ** \nd:(Intercept) 47.540342   1.459890 32.5643 0.000005302 ***\ne:(Intercept)  7.220130   2.340119  3.0854    0.036739 *  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error:\n\n 1.993805 (4 degrees of freedom)\n\nplot(drc1)\n\n\n\nED(drc1, 50, interval = \"delta\")\n\n\nEstimated effective doses\n\n       Estimate Std. Error    Lower    Upper\ne:1:50  7.22013    2.34012  0.72292 13.71734\n\n\n\nlibrary(ec50estimator)\n\ndf_ec50 <- estimate_EC50(GC_mean ~ Dose,\n                         data = dat2,\n                         isolate_col = \"Code\",\n                         interval = \"delta\",\n                         fct = drc::LL.3())\n\n\n## Função criada pelo Cha\n\ndf_ED50 <- function(formula, isolate_col, fct = LL.3(), ed_perc = 50, interval = \"delta\", data) {\n  # get the unique values of the isolate column\n  isolates <- unique(data %>% pull(isolate_col))\n\n  # apply drm() and ED() to each isolate\n  quiet_map <- quietly(map_df)\n  results <- quiet_map(\n    isolates, \n    ~{\n      # subset the data for the current isolate\n      isolate_data <- data %>% filter(!!sym(isolate_col) == .x)\n      \n      # apply drm()\n      drm_result <- drm(formula, data = isolate_data, fct = fct)\n      \n      # apply ED() and extract the EC50 value and its confidence interval\n      ed_result <- as.data.frame(ED(drm_result, ed_perc, interval = interval))\n      \n      # return as a data frame\n      tibble(\n        isolate = .x,\n        EC50 = ed_result[\"e:1:50\", \"Estimate\"],\n        lower = ed_result[\"e:1:50\", \"Lower\"],\n        upper = ed_result[\"e:1:50\", \"Upper\"]\n      )\n    }\n  )$result\n\n  return(results)\n}\n\nresults <- df_ED50(GC_mean ~ Dose, \n                   isolate_col = \"Code\", \n                   data = dat2)\n\n\n# print the results\nresults\n\n# A tibble: 12 × 4\n   isolate    EC50    lower  upper\n   <chr>     <dbl>    <dbl>  <dbl>\n 1 FGT152   7.22     0.723  13.7  \n 2 FGT169   0.577    0.0549  1.10 \n 3 FGT170   2.28     1.41    3.15 \n 4 FGT186   3.29    -1.15    7.72 \n 5 FGT187   0.0985  -0.0226  0.220\n 6 FGT189   9.30     2.29   16.3  \n 7 FGT201   4.93     0.172   9.68 \n 8 FGT202  13.8    -17.4    45.0  \n 9 FGT215   0.505    0.213   0.797\n10 FGT229   0.568   -0.241   1.38 \n11 FGT231   1.83     0.153   3.50 \n12 FGT232   0.340    0.105   0.575"
  }
]